{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (r2_score, mean_absolute_error)\n",
    "\n",
    "from mip import Model, xsum, maximize, BINARY, OptimizationStatus\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build prediction model *Can be modified*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = pd.read_csv(\"../data/interim/transactions_sd_knits_resampled_engin_synth_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unseen_data(df):\n",
    "    '''\n",
    "    Creates a copy of 'unseen data', that is not used to train the model. 'unseen data' is used to compare real prices to predicted optimal prices.\n",
    "        Parameters:\n",
    "            df (df): Dataframe from which to extract 'unseen data'. \n",
    "        Returns:\n",
    "            df (df): Dataframe containing unseen data.\n",
    "    '''\n",
    "    unseen_data = df[df['transaction_date'] >= '2021-10-3']\n",
    "    return unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = create_unseen_data(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT ADD TO CLASS\n",
    "def prepare_data(df):\n",
    "    knit_data['transaction_date'] = pd.to_datetime(knit_data['transaction_date'], infer_datetime_format=True)\n",
    "    knit_data['week_no'] = knit_data['week_no'].astype('object')\n",
    "    knit_data['review'] = knit_data['review'].astype('object')\n",
    "    knit_data.drop(columns=['month'], inplace=True)\n",
    "    knit_data.drop(columns=['p_id'], inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = prepare_data(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_categorical_aa(df):\n",
    "    '''\n",
    "    One hot encodes categorical variables.\n",
    "        Parameters:\n",
    "            df (df): Dataframe to one hot encode.\n",
    "        Returns:\n",
    "            df_encoded (df): Dataframe including one hot encoded \n",
    "            ohe_dropped_cols (list): List of one hot encoded columns that were dropped to get k-1 columns.\n",
    "    '''\n",
    "    df_encoded = pd.get_dummies(df) \n",
    "    # drop columns to get k-1 columns for \n",
    "    ohe_dropped_cols = ['week_no_2', 'label_desc_lab_1', 'color_simple_Other', 'review_0.0']\n",
    "    df_encoded.drop(columns=ohe_dropped_cols, \n",
    "                    axis=1, \n",
    "                    inplace=True)\n",
    "    return df_encoded, ohe_dropped_cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data, ohe_dropped_cols = one_hot_encode_categorical_aa(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT ADD TO CLASS\n",
    "def log_price_quantity(df):\n",
    "# take log of price and quantity, drop original columns\n",
    "    df['price_log'] = np.log(df['price'] + 1)\n",
    "    df['quantity_log'] = np.log(df['quantity'] + 1)\n",
    "    df.drop(columns=['price'], inplace=True)\n",
    "    df.drop(columns=['quantity'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = log_price_quantity(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prediction_model(df):\n",
    "    '''\n",
    "    Builds and returns a centralised random forest model based on best parameters, trained on dates that are treated as 'historic',\n",
    "    Also returns training data.\n",
    "        Parameters:\n",
    "            df (df): Dataframe from which to extract 'historic' data.\n",
    "        Returns:\n",
    "            RF_cen_model (model): RandomForestRegressor.fit() object.\n",
    "            X_train (df): Dataframe used to train random forest model.\n",
    "            y_train (df): Dataframe used to train random forest model.\n",
    "\n",
    "    '''\n",
    "    df_train = df[df['transaction_date'] < '2021-10-3']\n",
    "    y_train = df_train['quantity_log']\n",
    "    X_train = df_train.drop(['quantity_log', 'transaction_date'], axis=1)\n",
    "\n",
    "    RF_cen_model = RandomForestRegressor(max_features=50, \n",
    "                                        max_depth=6, \n",
    "                                        n_estimators=820, \n",
    "                                        random_state=0,\n",
    "                                        min_samples_split=2,\n",
    "                                        min_samples_leaf=2,\n",
    "                                        criterion='squared_error',\n",
    "                                        bootstrap=False\n",
    "                                        ).fit(X_train, y_train)\n",
    "\n",
    "    return RF_cen_model, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_cen_model, X_train_historic, y_train_historic = build_prediction_model(knit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply model to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_X_unseen(X_historic, week_no, label_desc, color_simple, price, relative_price, ohe_dropped_cols=ohe_dropped_cols):\n",
    "    '''\n",
    "    Builds dataframe containing one row, which is used to predict demand for 'unseen'/future items.\n",
    "        Parameters:\n",
    "            X_historic (df): Dataframe used to train random forest model.\n",
    "            week_no (int): Week in which 'unseen'/future item is to be sold. For testing pipeline, values between 44 - 52 are sensible.\n",
    "            label_desc (object): Label to which 'unseen'/future item belongs. Takes the following values: 'lab_1', 'lab_2', 'lab_3', 'lab_4'.\n",
    "            color_simple (object): Colour of 'unseen'/future item. Takes the following values: 'White', 'Pink', 'Black', 'Other', 'Blue', \n",
    "                                    'Zebra', 'Yellow', 'Green', 'Brown', 'Cream'.\n",
    "            price (float): Suggested price of 'unseen'/future item.\n",
    "            relative_price (float): Suggested relative price of 'unseen'/future item.\n",
    "            ohe_dropped_cols (list): List of one hot encoded columns that were dropped in data preparation.\n",
    "        Returns:\n",
    "            X_unseen (df): Dataframe used to predict demand for an 'unseen' item.\n",
    "    '''\n",
    "# TODO throw error if variables other than those expected are shown e.g. a new label, new colour, unknown week\n",
    "\n",
    "    # create output df with same colnames as training data, add in one hot encoded columns that were dropped in previous steps\n",
    "    columns_all = list(X_historic.columns) \n",
    "    columns_all += ohe_dropped_cols\n",
    "    X_unseen = pd.DataFrame(columns=columns_all)\n",
    "    row_dict = {'price_log' : np.log(price + 1), 'price_comp_week' : relative_price}\n",
    "    X_unseen = X_unseen.append(row_dict, ignore_index=True)\n",
    "\n",
    "    # fill in one hot encoded columns\n",
    "    week_no_match = 'week_no_' + str(week_no)\n",
    "    X_unseen[week_no_match] = 1\n",
    "    \n",
    "    label_desc_match = 'label_desc_' + label_desc\n",
    "    X_unseen[label_desc_match] = 1\n",
    "\n",
    "    color_simple_match = 'color_simple_' + color_simple\n",
    "    X_unseen[color_simple_match] = 1\n",
    "\n",
    "    # add label and colour columns back into historic data \n",
    "    X_historic['label_desc_lab_1'] = np.where(X_historic[['label_desc_lab_2', 'label_desc_lab_3', 'label_desc_lab_4']].sum(axis=1) == 0, 1, 0)\n",
    "    X_historic['color_simple_Other'] = np.where(X_historic[['color_simple_Black', 'color_simple_Blue','color_simple_Brown', 'color_simple_Cream', \n",
    "                                                            'color_simple_Green','color_simple_Pink', 'color_simple_White', 'color_simple_Yellow', \n",
    "                                                            'color_simple_Zebra']].sum(axis=1) == 0, 1, 0)\n",
    "\n",
    "    # for rating, google trend, and review field, take the median value from historic data based on label and item colour as this information would not be available for \n",
    "    # predicting demand live\n",
    "    # TODO if historic data for 1+ years is available, match based on week too - this should give better predictive demand prediction\n",
    "    if X_historic[(X_historic[label_desc_match] == 1) & (X_historic[color_simple_match] == 1)].shape[0] > 0:\n",
    "        X_unseen['star_rating'] = X_historic[(X_historic[label_desc_match] == 1) & (X_historic[color_simple_match] == 1)]['star_rating'].median()\n",
    "        X_unseen['google_trends_knit'] = X_historic[(X_historic[label_desc_match] == 1) & (X_historic[color_simple_match] == 1)]['google_trends_knit'].median()\n",
    "        X_unseen['google_trends_colour'] = X_historic[(X_historic[label_desc_match] == 1) & (X_historic[color_simple_match] == 1)]['google_trends_colour'].median()\n",
    "        neg_rev_av = X_unseen['review_-1.0'] = X_historic[(X_historic[label_desc_match] == 1) & (X_historic[color_simple_match] == 1)]['review_-1.0'].median()\n",
    "        pos_rev_av = X_unseen['review_1.0'] = X_historic[(X_historic[label_desc_match] == 1) & (X_historic[color_simple_match] == 1)]['review_1.0'].median()\n",
    "        if neg_rev_av > pos_rev_av:\n",
    "            X_unseen['review_-1.0'] = 1\n",
    "            X_unseen['review_1.0'] = 0\n",
    "        else:\n",
    "            X_unseen['review_-1.0'] = 0\n",
    "            X_unseen['review_1.0'] = 1\n",
    "    \n",
    "    # if a label and colour combination hasn't been seen before take the median all historic data \n",
    "    # this would be more meaningful if historic data for 1+ years was available and could be matched for week \n",
    "    else: \n",
    "        X_unseen['star_rating'] = X_historic['star_rating'].median()\n",
    "        X_unseen['google_trends_knit'] = X_historic['google_trends_knit'].median()\n",
    "        X_unseen['google_trends_colour'] = X_historic['google_trends_colour'].median()\n",
    "        neg_rev_av = X_unseen['review_-1.0'] = X_historic['review_-1.0'].median()\n",
    "        pos_rev_av = X_unseen['review_1.0'] = X_historic['review_1.0'].median()\n",
    "\n",
    "        if neg_rev_av > pos_rev_av:\n",
    "            X_unseen['review_-1.0'] = 1\n",
    "            X_unseen['review_1.0'] = 0\n",
    "\n",
    "        else:\n",
    "            X_unseen['review_-1.0'] = 0\n",
    "            X_unseen['review_1.0'] = 1\n",
    "\n",
    "\n",
    "    # fill remaining NAs with 0\n",
    "    X_unseen = X_unseen.fillna(0)\n",
    "\n",
    "    # drop one hot encoded that were added in earlier step\n",
    "    X_unseen.drop(columns=ohe_dropped_cols, inplace=True)\n",
    "\n",
    "    # drop columns that were added onto historic data\n",
    "    X_historic.drop(columns=['label_desc_lab_1', 'color_simple_Other'], inplace=True)\n",
    "\n",
    "    # order columns correctly\n",
    "    X_unseen = X_unseen[X_historic.columns]\n",
    "\n",
    "    return X_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_demand(X_unseen):\n",
    "    '''\n",
    "    Predicts demand for input data.\n",
    "        Parameters:\n",
    "            X_unseen: Dataframe containing 1 row.\n",
    "        Returns:\n",
    "            prediction: Prediction for 'unseen'/future item as an interpretable value.\n",
    "    '''\n",
    "    prediction = RF_cen_model.predict(X_unseen)\n",
    "    prediction = np.exp(prediction) - 1\n",
    "    prediction = np.round(prediction)\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select competing products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data.groupby(['week_no']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test/unseen data is from week 44 - 52\n",
    "def select_competing_products(unseen_data, n_products, week_no, pc_lower_price_bound, pc_upper_price_bound, random_state):\n",
    "    '''\n",
    "    Randomly selects competing products and related features to test demand prediction and optimisation step.\n",
    "        Parameters:\n",
    "            unseen_data (df): Dataframe from which to randomly select competing items. This should be the 'unseen'/future data.\n",
    "            n_products (int): Number of competing items to select. This should not be greater than the number of items that were actually sold for a particular week.\n",
    "            week_no (int): Week number to select competing items from. For testing pipeline, values between 44 - 52 are sensible.\n",
    "            pc_lower_price_bound (int): Percentage value by which to lower the price of an item for testing price optimisation.\n",
    "            pc_upper_price_bound (int): Percentage value by which to increase the price of an item for testing price optimisation.\n",
    "            random_state (int): Random state for reproducibility.\n",
    "        Returns:\n",
    "            competing_items_dict (dict): A dictionary of competing items, including item features such as week of same, label, colour, lower price bound and upper \n",
    "                                         price bound. \n",
    "    '''\n",
    "    unseen_data = unseen_data[unseen_data['week_no'] == week_no]\n",
    "    unseen_sample = unseen_data.sample(n=n_products, replace=False, random_state=random_state)\n",
    "    unseen_sample_details = unseen_sample[['week_no', 'label_desc', 'color_simple', 'price']].reset_index(drop=True)\n",
    "  \n",
    "    competing_items_dict = {}\n",
    "    for i in range(len(unseen_sample_details)):\n",
    "        prod_name = 'unseen_' + str(i+1)\n",
    "        price = unseen_sample_details.iloc[i][3]\n",
    "        lpb = round(price - (price * (pc_lower_price_bound/100)), 2)\n",
    "        upb = round(price + (price * (pc_upper_price_bound/100)), 2)\n",
    "        array = [unseen_sample_details.iloc[i][0], unseen_sample_details.iloc[i][1], unseen_sample_details.iloc[i][2], lpb, upb]\n",
    "        competing_items_dict[prod_name] = array\n",
    "\n",
    "    return competing_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_revenue_get_prices(unseen_data, n_products, week_no, random_state):\n",
    "    '''\n",
    "    Calculates and returns total revenue and returns prices for competing products, input should match those used in select_competing_products().\n",
    "        Parameters:\n",
    "            unseen_data (df): Dataframe from which to randomly select competing items. This should be the 'unseen'/future data.\n",
    "            n_products (int): Number of competing items to select. This should not be greater than the number of items that were actually sold for a particular week.\n",
    "            week_no (int): Week number to select competing items from. For testing pipeline, values between 44 - 52 are sensible.\n",
    "            random_state (int): Random state for reproducibility.\n",
    "        Returns:\n",
    "            total_revenue (float): Total revenue for competing items in specified week.\n",
    "            actual_prices (list): Prices for competing items in specified week.\n",
    "\n",
    "    '''\n",
    "    unseen_data = unseen_data[unseen_data['week_no'] == week_no]\n",
    "    unseen_sample = unseen_data.sample(n=n_products, replace=False, random_state=random_state)\n",
    "    unseen_sample['revenue'] = unseen_sample['price'] * unseen_sample['quantity']\n",
    "    total_revenue = round(unseen_sample['revenue'].sum(), 2)\n",
    "    actual_prices = list(round(unseen_sample['price'], 2))\n",
    "\n",
    "    return total_revenue, actual_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_items_dict = select_competing_products(unseen_data=unseen_data, n_products=8, week_no=48, pc_lower_price_bound=10, pc_upper_price_bound=20, random_state=0)\n",
    "total_revenue, actual_prices = calc_revenue_get_prices(unseen_data=unseen_data, n_products=8, week_no=48, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_items_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build demand matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_demand_matrix(min_price, max_price, increment, competing_items_dict, X_historic):\n",
    "    '''\n",
    "    Builds and returns array of prices, sum_prices and 3D matrix of demand predictions to be input into the price optimisation step.\n",
    "        Parameters:\n",
    "            min_price (int): Minimum price to consider for items when predicitng their demand.\n",
    "            max_price (int): Maximum price to consider for items when predicitng their demand.\n",
    "            increment (int): Increment by which to increase searched prices for predicting demand.\n",
    "            competing_items_dict (dict): Dictionary of competing items, including item features such as week of same, label, colour, lower price bound and upper \n",
    "                                         price bound.\n",
    "            X_historic (df): Dataframe used to train random forest model.\n",
    "        Returns:\n",
    "            demand_matrix (ndarray): Predicted demands matrix of dimension (n,k,j) with n the # of items, k the # of price possibilities, \n",
    "                                     and j # the number of sum of prices considered\n",
    "            prices (ndarray): 1D-array containing the 'k' possible prices to attribute to the items.\n",
    "            sum_prices (ndarray): 1D-array containing the sum of prices considered.\n",
    "    '''\n",
    "\n",
    "    competing_items = len(competing_items_dict)\n",
    "    competing_items_keys = list(competing_items_dict.keys())\n",
    "    prices = list(range(min_price, max_price+increment, increment))\n",
    "    sum_prices = np.arange(min_price*competing_items, max_price*competing_items+increment, increment)\n",
    "\n",
    "    demand_matrix = np.zeros((competing_items, len(prices), len(sum_prices)))\n",
    "\n",
    "    for nn in range(competing_items):\n",
    "        week_no = competing_items_dict[competing_items_keys[nn]][0]\n",
    "        label_desc = competing_items_dict[competing_items_keys[nn]][1]\n",
    "        color_simple = competing_items_dict[competing_items_keys[nn]][2]\n",
    "        lpb = competing_items_dict[competing_items_keys[nn]][3]\n",
    "        upb = competing_items_dict[competing_items_keys[nn]][4]\n",
    "        \n",
    "        for j2, jj in enumerate(prices):\n",
    "            \n",
    "            for k2, kk in enumerate(sum_prices):\n",
    "                \n",
    "                if (jj >= lpb) & (jj <= upb):\n",
    "                    relative_price =  jj/(kk/competing_items)\n",
    "\n",
    "                    # TODO this can be sped up\n",
    "                    X_unseen = build_X_unseen(X_historic = X_historic, \n",
    "                                        week_no=week_no, \n",
    "                                        label_desc=label_desc, \n",
    "                                        color_simple=color_simple, \n",
    "                                        price=jj, \n",
    "                                        relative_price=relative_price\n",
    "                                        )\n",
    "\n",
    "                    demand_matrix[nn,j2,k2] = predict_demand(X_unseen)\n",
    "                \n",
    "                else:\n",
    "                    demand_matrix[nn,j2,k2] = 0\n",
    "\n",
    "    return demand_matrix, np.array(prices), sum_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_matrix, prices, sum_prices = build_demand_matrix(min_price=20, max_price=370, increment=2, competing_items_dict=competing_items_dict, X_historic=X_train_historic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demand_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT ADD TO CLASS\n",
    "def lp_mip_solver(demands,prices,sum_prices):\n",
    "\n",
    "# the function takes three inputs. \n",
    "# demands: matrix of size 'n*k*j' with n the # of items, k the # of price possibilities, and j # the number of sum of prices considered   \n",
    "# prices: list of 'k' possible prices \n",
    "# sum_prices: vector typically ranging from n*min(prices) to n*max(prices) \n",
    "    \n",
    "    n, k, num_loops = np.shape(demands) # n corresponds to the number of products and k to the number of prices considered in the optimisation problem\n",
    "\n",
    "\n",
    "    # sanity check\n",
    "    assert  num_loops == len(sum_prices), 'the demands matrix last dimension is different from len(sum_prices)'\n",
    "    assert  k == len(prices), 'the demands matrix middle dimension is different from len(prices)'\n",
    "\n",
    "\n",
    "    # initialising empty variables\n",
    "    optimum_solution = np.zeros(n*k) # optimum solution \n",
    "    revenue_prediction = 0 # optimum revenue\n",
    "\n",
    "        \n",
    "\n",
    "    # Constraints are recast out of the shape A*x = b. \n",
    "    # Two types of constraints are considered. The sum of the prices of a single item must be equal to 1 (for a binary variable this means that an item has only a single price!)\n",
    "    A = np.array([[\n",
    "        1 if j >= k*(i) and j < k*(i+1) else 0\n",
    "        for j in range(k*n)\n",
    "    ] for i in range(n)])\n",
    "\n",
    "\n",
    "    # The second set of constraints is defined and added to A here: The sum of the prices must be equal to sum_prices[aa]\n",
    "    A = np.append(A, np.tile([prices], n), axis=0)\n",
    "\n",
    "\n",
    "    objective_loop, LBk = loop_k(demands, prices, sum_prices, A)\n",
    "\n",
    "    # step 2 (LP bound Algorithm) in `Analytics for an Online Retailer: Demand Forecasting and Price Optimization`\n",
    "    sum_prices_sorted = sum_prices[np.argsort(objective_loop)[::-1]]\n",
    "    objective_sorted = objective_loop[np.argsort(objective_loop)[::-1]]\n",
    "    demands_sorted = demands[:,:,np.argsort(objective_loop)[::-1]]\n",
    "    LBk_sorted = LBk[np.argsort(objective_loop)[::-1]]\n",
    "\n",
    "    \n",
    "    # step 3 (LP bound Algorithm)\n",
    "    k_hat = np.argmax(LBk_sorted)\n",
    "    LB = LBk_sorted[k_hat]\n",
    "\n",
    "    ll = 0\n",
    "    flag = True\n",
    "    while flag == True: # looping voer the MIP probelm while flag == True\n",
    "        \n",
    "        demands_submatrix = demands_sorted[:,:,ll]\n",
    "        r = np.multiply(np.tile([prices], n), np.array(demands_submatrix).reshape(1, k*n)).flatten()\n",
    "        b = [np.append(np.ones(n), sum_prices_sorted[ll])] # constraint vector: [1....1 sum_prices[ll]]\n",
    "        m = Model() # calling the model object and initiation\n",
    "\n",
    "        x = [m.add_var(var_type=BINARY) for i in range(k*n)] # defining the different variables: n*k variables and defining them as binary\n",
    "\n",
    "        m.objective = maximize(xsum(r[i] * x[i] for i in range(k*n))) # objective function defined as r*x to be maximised\n",
    "\n",
    "        for j in range(n+1): # adding the different constraints to the problem Ax = b\n",
    "            m += xsum(A[j,i] * x[i] for i in range(n*k)) == b[0][j]\n",
    "\n",
    "        status = m.optimize() # calling the solver\n",
    "\n",
    "        if status == OptimizationStatus.OPTIMAL and m.objective_value > LB:\n",
    "            k_hat = ll\n",
    "            LB = m.objective_value\n",
    "            revenue_prediction = m.objective_value # then we want this to be our objective\n",
    "            optimum_solution = np.array([ x[aa].x for aa in range(n*k)]) #recording the solution\n",
    "        \n",
    "        if ll==num_loops-1:\n",
    "            flag = False\n",
    "        elif status == OptimizationStatus.OPTIMAL and LB >= objective_sorted[ll+1]:\n",
    "            flag = False\n",
    "        else:\n",
    "            ll+=1\n",
    "            \n",
    "            \n",
    "    optimal_prices = np.matmul(optimum_solution.reshape(n,k),prices) # returning the vector of optimum prices for each item\n",
    "\n",
    "    return optimal_prices, revenue_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT ADD TO CLASS\n",
    "def loop_k(demands, prices, sum_prices, A):\n",
    "    # function where the loop over the different values of the sum of the prices: sum_prices[aa] is executed\n",
    "    \n",
    "    \n",
    "    n, k, num_loops = np.shape(demands) \n",
    "\n",
    "    \n",
    "    # r is the vector giving the different price * demand combinations \n",
    "    # It is used to define the cost function to maximise: max_x( tranpose(r) * x )\n",
    "\n",
    "    #initialisation\n",
    "    objective_loop = np.zeros(len(sum_prices)) # best objective function in each solution\n",
    "    LBk = np.zeros(len(sum_prices))\n",
    "\n",
    "    for aa in range(num_loops): \n",
    "        demands_submatrix = demands[:,:,aa]\n",
    "        r = np.multiply(np.tile([prices], n), np.array(demands_submatrix).reshape(1, k*n))\n",
    "\n",
    "        b = [np.append(np.ones(n), sum_prices[aa])] # constraint vector: [1....1 sum_prices[aa]]\n",
    "        \n",
    "        lp_sol = linprog(-r.flatten(), A_eq = A, b_eq = b) # calling the model object and initiation\n",
    "        \n",
    "\n",
    "        if lp_sol.status == 0:\n",
    "            objective_loop[aa] = -lp_sol.fun\n",
    "            LBk[aa] = -lp_sol.fun - np.max( np.max(prices*demands_submatrix,axis=1) - np.min(prices*demands_submatrix,axis=1) )\n",
    "    \n",
    "\n",
    "    \n",
    "    return objective_loop, LBk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_loop, LBk = lp_mip_solver(demand_matrix, np.array(prices), sum_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Real Prices:' + str(actual_prices) + '\\nReal Revenue: ' + str(total_revenue) + '\\nPredicted Prices :' + str(objective_loop) + '\\nPredicted Revenue: ' + str(LBk))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57727d540d2cdea30e42da3b647feb3a70b95224e671f1550702dd816d97d117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
