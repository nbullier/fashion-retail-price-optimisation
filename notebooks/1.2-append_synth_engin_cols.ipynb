{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import (datetime as dt, timedelta)\n",
    "#import datetime\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = \"../data/interim\" \n",
    "knit_data = pd.read_csv(\"../data/interim/transactions_sd_knits_resampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data['transaction_date'] = pd.to_datetime(knit_data['transaction_date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### engineer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_columns(df):\n",
    "    '''\n",
    "    Attaches engineered columns including 'week_no', 'month', 'price' per week, 'price_comp_week' and 'transaction_date' for the first Sunday of a week.\n",
    "        Parameters:\n",
    "            df (df): Dataframe to engineer and attach columns to.\n",
    "        Returns:\n",
    "            df (df): Dataframe with engineered columns attached.\n",
    "    '''\n",
    "    # sort data\n",
    "    df = df.sort_values(by=['p_id', 'transaction_date'])\n",
    "\n",
    "    # add week no\n",
    "    df['week_no'] = df['transaction_date'].dt.strftime('%U')\n",
    "\n",
    "    # concatenate by week and sum quantity \n",
    "    knit_data_week = df.groupby(['p_id', 'week_no', 'sub_department_desc', 'label_desc', 'color_simple'])['quantity'].sum().to_frame('quantity').reset_index()\n",
    "\n",
    "    # Calculate price as average of amount per week / quantity\n",
    "    sum_amount_week = df.groupby(['p_id', 'week_no', 'sub_department_desc', 'label_desc', 'color_simple'])['amount'].sum().to_frame('sum_amount').reset_index()\n",
    "    knit_data_week = pd.merge(knit_data_week, sum_amount_week, on=['p_id', 'week_no', 'sub_department_desc', 'label_desc','color_simple'], how='left')\n",
    "    knit_data_week['price'] = knit_data_week['sum_amount']/knit_data_week['quantity']\n",
    "    knit_data_week.drop(columns=['sum_amount'], inplace=True)\n",
    "    df = knit_data_week\n",
    "\n",
    "    # engineer price competition column per week \n",
    "    price_mean_week = df.groupby(['week_no'])['price'].mean().to_frame(\"mean_price_week\").reset_index()\n",
    "    df = pd.merge(df, price_mean_week, on='week_no', how='left')\n",
    "    df['price_comp_week'] = df['price']/df['mean_price_week']\n",
    "    df.drop(columns=['mean_price_week'], inplace=True)\n",
    "\n",
    "    # add date for first sunday back in\n",
    "    def find_sunday(week):\n",
    "        ref = '2021-01-03' #reference date corresponding to the 1st Sunday in 2021\n",
    "        ref_object = dt.strptime(ref,'%Y-%m-%d') #reference day converted in datetime object\n",
    "        day_object = ref_object + timedelta(days=(week-1)*7) # adding the number of days\n",
    "        day=day_object.strftime('%Y-%m-%d') # converting back to the desired format\n",
    "        return day\n",
    "\n",
    "    df['transaction_date'] = df['week_no'].apply(lambda x : find_sunday(int(x)))\n",
    "\n",
    "    # add month column\n",
    "    df['transaction_date'] = pd.to_datetime(df['transaction_date'], infer_datetime_format=True)\n",
    "    df['month'] = df['transaction_date'].dt.strftime('%b')\n",
    "\n",
    "    df = df.sort_values(by=['p_id', 'transaction_date'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = engineer_columns(knit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function - star rating and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesise_star_sentiment(df, random_seed=123, star_dist = [0.03675, 0.06773, 0.12719, 0.23374, 0.53459]):\n",
    "    '''\n",
    "    Returns two synthetic features i) star_rating (1-5) randomly assigned based on the distribution profile \n",
    "    of star ratings given to women's knitwear in the following dataset:\n",
    "    https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews?datasetId=11827&sortBy=voteCount\n",
    "    Future star rating could be assigned to a transaction based on the average rating of an item at the time of transaction.\n",
    "    ii) review sentiment, -1 for negative, 0 for neutral and 1 for positive, assigned to transaction based on\n",
    "    star rating. Distribution of assignment was based on educated guess. In future actual reviews could be analysed\n",
    "    by Natural language processing to determine the average review sentiment of an item at the time of tranaction.\n",
    "        \n",
    "            Parameters:\n",
    "                df (dataframe): Dataframe to append new features of star rating and review sentiment\n",
    "                random_seed (int): Random number (default is 123)\n",
    "                star_dist (list): List of floats which represent the distribution profile\n",
    "            Returns:\n",
    "                df (dataframe): Dataframe with appended columns 'star_rating' for assigned star rating and                \n",
    "                 'review' to capture review sentiment \n",
    "    '''\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    df['star_rating'] = np.nan\n",
    "\n",
    "    df['star_rating'] = np.random.choice([1, 2, 3, 4, 5], size=df.shape[0], replace=True, p=star_dist) \n",
    "    \n",
    "    mask1 = df['star_rating'] >= 4\n",
    "    mask2 = (df['star_rating'] < 4) & (df['star_rating'] >= 2)\n",
    "    mask3 = df['star_rating'] < 2\n",
    "\n",
    "    df.loc[mask1, 'review'] = 1\n",
    "    df.loc[mask2, 'review'] = np.random.choice([-1, 0, 1], replace = True, p=[.2, .65, .15])\n",
    "    df.loc[mask3, 'review'] = np.random.choice([-1, 0, 1], replace = True, p=[.9, .08, .02])\n",
    "\n",
    "    df['review'] = df['review'].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "#star_dist_sales = [0, 0.07, 0.14, 0.24, 0.55]\n",
    "#star_dist_returns = [0.18, 0.2, 0.26, 0.36, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synthesise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = synthesise_star_sentiment(df=knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data['star_rating'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data['review'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to download google trends data and convert to interest rate of change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = ['Black Knit', 'White Knit', 'Zebra Knit', 'Blue Knit', 'Green Knit',\n",
    "            'Pink Knit', 'Yellow Knit', 'Cream Knit', 'Brown Knit']\n",
    "\n",
    "search_start = '2020-12-27 ' \n",
    "search_end = '2021-12-31'\n",
    "\n",
    "def get_google_trends(search_list, search_start, search_end):\n",
    "    '''\n",
    "    Returns new dataframe of google trend's weekly interest over time of a search term in search list. \n",
    "    Values are relative to the highest search volume of that term in the defined time period in a given \n",
    "    georgraphical region (here GB). A value of 100 is the peak popularity for the term, 50 means that \n",
    "    the term is half as popular. A score of 0 means that there was not enough data for this term. Designed \n",
    "    for function to be run for each new google_trend feature to be added to the dataframe, which is paired \n",
    "    to another feature in the dataframe, with a search list containing the categorical column options.  \n",
    "    \n",
    "            Parameters:\n",
    "                search_list (list of str): Terms to be searched - corresponds to different categorical \n",
    "                search_start (str): date in 'YYYY-MM-DD' to avoid NaN downstream date should be two weeks before \n",
    "                                    start of corresponding transactions dataframe\n",
    "                search_end (str): date in 'YYYY-MM-DD'\n",
    "\n",
    "            Returns:\n",
    "                dataframe of all search terms with google ternds relative interest over specified time period\n",
    "    '''\n",
    "\n",
    "    pytrend = TrendReq(hl='en-UK', tz=0)\n",
    "    trends_dict = {}\n",
    "    df_trends = pd.DataFrame()\n",
    "\n",
    "    for term in search_list:\n",
    "        pytrend.build_payload(\n",
    "        kw_list=[term],\n",
    "        cat=0,\n",
    "        geo='GB-ENG',\n",
    "        timeframe=(search_start+search_end))\n",
    "        trends_dict[term] = pytrend.interest_over_time()\n",
    "\n",
    "    df_trends = pd.concat([trends_dict[key] for key in search_list], join = 'inner', axis =1)\n",
    "    return df_trends.drop(labels=['isPartial'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google trends interest relative to the first week of 2021 \n",
    "def calculate_google_trend_term_relative_to_week_1(df):    \n",
    "    '''\n",
    "    Returns google trend dataframe with interest over time relative to the interest in first week in 2021\n",
    "\n",
    "            Parameters:\n",
    "                df (dataframe): google trends dataframe\n",
    "\n",
    "            Returns:\n",
    "                df (dataframe): google trends dataframe with values relative to week 1 2021\n",
    "\n",
    "    ''' \n",
    "    return df.div(df.iloc[1]) # Week1 2021 is not first row of this dataframe hence position [1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_of_change_of_google_trend_term(df):\n",
    "    '''\n",
    "    Function to compare current google trend information to the 3 week moving average as a rate of change \n",
    "    Negative values imply term is searched less than the 3 week moving average, Positive values, more than.\n",
    "    NB: Not used in the end for the project - maybe useful for an ARIMA model?\n",
    "\n",
    "            Parameters:\n",
    "                df (dataframe): google trends dataframe\n",
    "\n",
    "            Returns:\n",
    "                df_diff_MA (dataframe): google trends dataframe with interest values relative to 3 week moving average\n",
    "    '''\n",
    "    \n",
    "    moving_dict = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        moving_dict[col] = df[col].rolling(3, min_periods=3).mean()\n",
    "    df_moving_average = pd.concat([moving_dict[col] for col in df.columns], join = 'inner', axis=1)   \n",
    "\n",
    "    df_diff_MA = df.subtract(df_moving_average, axis=1)\n",
    "\n",
    "    return df_diff_MA.div(df_moving_average, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to expand out trends from week to days \n",
    "def make_trends_daily(df, search_start, search_end):\n",
    "    '''\n",
    "    Returns expanded google trends dataframe on daily rather than weekly basis \n",
    "    (forward fill of sunday value)\n",
    "\n",
    "            Parameters:\n",
    "                df (dataframe): google trends dataframe with values relative to week 1 2021\n",
    "\n",
    "            Returns:\n",
    "                df (dataframe): daily google trends dataframe with values relative to week 1 2021 \n",
    "\n",
    "    '''\n",
    "    \n",
    "    date_range = pd.date_range(start=search_start, end=search_end)\n",
    "    return df.reindex(date_range).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google trend feature for colour of knit\n",
    "trend_df = get_google_trends(search_list, search_start, search_end)  \n",
    "colour_trend = calculate_google_trend_term_relative_to_week_1(trend_df)\n",
    "colour_trend_daily = make_trends_daily(colour_trend, search_start, search_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google trend feature relating to style of 'knits'\n",
    "style_knits = get_google_trends(['Knits'], search_start, search_end)   \n",
    "trend_knits = calculate_google_trend_term_relative_to_week_1(style_knits) \n",
    "knits_trend_daily = make_trends_daily(trend_knits, search_start, search_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to feature on the transactions dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knits_transactions = pd.read_csv(\"../data/interim/transactions_sd_knits_resampled_synth.csv\") ### aminah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knits_transactions['transaction_date'] = knits_transactions['transaction_date'].apply(pd.to_datetime) ### aminah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to add sub department knits google trend\n",
    "TOFIX: This will not work if more than one sub department is presented to be searched for in the google trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_google_trends_sub_depart_feature(df_transactions, df_google_trends):\n",
    "    '''\n",
    "    Returns column appended to transaction data frame with the google trend interest of the subdepartment \n",
    "    term ie 'knits' based on the date of transaction. NB this for use of appending google trends\n",
    "    data where there is only one search term otherwise use function append_google_trends_colour_feature. \n",
    "\n",
    "            Parameters:\n",
    "                df_transactions (dataframe): dataframe with tranactions and physical attributes of items\n",
    "                df_google_trends (dataframe): daily google trends dataframe with values relative to week 1 2021 \n",
    "\n",
    "                \n",
    "            Returns:\n",
    "                df_trans_gt_knit (dataframe): transactions dataframe with appended 'google_trend_knit' variable\n",
    "\n",
    "    '''\n",
    "    \n",
    "    df_google_trends.reset_index(inplace=True)\n",
    "\n",
    "    df_trans_gt_knit = df_transactions.merge(df_google_trends, \n",
    "                                            left_on='transaction_date', \n",
    "                                            right_on='index', \n",
    "                                            how='left')\n",
    "    \n",
    "    df_trans_gt_knit.drop(columns=['index'], inplace=True)  \n",
    "    df_trans_gt_knit.rename(columns={'Knits':'google_trends_knit'}, inplace=True)\n",
    "    \n",
    "    return df_trans_gt_knit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knits_transactions_gt_knits = append_google_trends_sub_depart_feature(knit_data, knits_trend_daily) ### aminah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_google_trends_colour_feature(df_transactions, df_google_trends):\n",
    "    '''\n",
    "    Returns transaction dataframe with the appropriate google_trends value based on the colour in 'color_simple' \n",
    "    and the transaction date for each transaction. \n",
    "\n",
    "            Parameters:\n",
    "                df_transactions (dataframe): dataframe with tranactions and physical attributes of items\n",
    "                df_google_trends (dataframe): daily google trends dataframe with values relative to week 1 2021 \n",
    "\n",
    "            Returns:\n",
    "                df_transactions (dataframe): transactions dataframe with appended 'google_trend_colour' variable\n",
    "\n",
    "    '''\n",
    "    \n",
    "    df_transactions['google_trends_colour'] = np.nan\n",
    "\n",
    "    df_google_trends.columns = df_google_trends.columns.str.replace(' Knit', '')\n",
    "\n",
    "    for i, row in df_transactions.iterrows():\n",
    "\n",
    "        # get date and color in transactions\n",
    "        transaction_date = f\"{row['transaction_date']}\"\n",
    "        x = f\"{row['color_simple']}\"\n",
    "\n",
    "        if x != 'Other':\n",
    "        # get correct colour column\n",
    "            gt_colour = df_google_trends[df_google_trends.columns[df_google_trends.columns.isin([x])]]\n",
    "            gt_colour.reset_index(inplace=True)\n",
    "\n",
    "            mask = gt_colour['index'] == transaction_date\n",
    "\n",
    "            gt = gt_colour.loc[mask, x]\n",
    "\n",
    "            gt = gt.values\n",
    "       \n",
    "            df_transactions['google_trends_colour'].iloc[i] = gt\n",
    "        else:\n",
    "            df_transactions['google_trends_colour'].iloc[i] = 0 # No change in other trend\n",
    "\n",
    "    return df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_google_trends_colour_feature(knits_transactions_gt_knits, colour_trend_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = knits_transactions_gt_knits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop knit column redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data.drop(columns=['sub_department_desc'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = knit_data[['p_id','transaction_date', 'week_no', 'month', 'label_desc', 'color_simple', 'quantity', \n",
    "        'price', 'price_comp_week', 'star_rating', 'review', 'google_trends_knit', 'google_trends_colour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort on date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = knit_data.sort_values(by=['transaction_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write to interim folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data.to_csv(\"../data/interim/transactions_sd_knits_resampled_engin_synth_gt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57727d540d2cdea30e42da3b647feb3a70b95224e671f1550702dd816d97d117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
