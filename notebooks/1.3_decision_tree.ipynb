{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import (DecisionTreeRegressor, plot_tree)\n",
    "from sklearn.metrics import (r2_score, mean_absolute_error)\n",
    "#from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = pd.read_csv(\"../data/interim/transactions_sd_knits_resampled_engin_synth_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data['price_log'] = np.log(knit_data['price'] + 1)\n",
    "knit_data['quantity_log'] = np.log(knit_data['quantity'] +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(3,2,figsize=(15,10))\n",
    "\n",
    "sns.histplot(knit_data['price'], bins=40, ax=ax[0,0])\n",
    "sns.histplot(knit_data['price_log'], bins=40, ax=ax[0,1])\n",
    "sns.histplot(knit_data['quantity'], bins=40, ax=ax[1,0])\n",
    "sns.histplot(knit_data['quantity_log'], bins=40, ax=ax[1,1])\n",
    "sns.scatterplot(data=knit_data, x='price', y='quantity', ax=ax[2,0])\n",
    "sns.scatterplot(data=knit_data, x='price_log', y='quantity_log', ax=ax[2,1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data.drop(columns=['price'], inplace=True)\n",
    "knit_data.drop(columns=['quantity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    knit_data['transaction_date'] = pd.to_datetime(knit_data['transaction_date'], infer_datetime_format=True)\n",
    "    knit_data['week_no'] = knit_data['week_no'].astype('object')\n",
    "    knit_data['review'] = knit_data['review'].astype('object')\n",
    "    knit_data.drop(columns=['month'], inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = prepare_data(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_categorical(df):\n",
    "    # one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df) \n",
    "    # drop columns to get k-1 columns for \n",
    "    df_encoded.drop(columns=['p_id_p_1', 'week_no_2', 'label_desc_lab_1', 'color_simple_Other', 'review_0.0'], \n",
    "                    axis=1, \n",
    "                    inplace=True)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = one_hot_encode_categorical(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data_full = knit_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data_red = knit_data.drop(columns=['star_rating', 'google_trends_knit', 'google_trends_colour',\n",
    "       'p_id_p_10', 'p_id_p_11', 'p_id_p_12', 'p_id_p_13', 'p_id_p_14',\n",
    "       'p_id_p_15', 'p_id_p_16', 'p_id_p_17', 'p_id_p_18', 'p_id_p_19',\n",
    "       'p_id_p_2', 'p_id_p_20', 'p_id_p_21', 'p_id_p_22', 'p_id_p_23',\n",
    "       'p_id_p_24', 'p_id_p_3', 'p_id_p_4', 'p_id_p_5', 'p_id_p_6', 'p_id_p_7',\n",
    "       'p_id_p_8', 'p_id_p_9', 'week_no_4', 'week_no_5', 'week_no_6',\n",
    "       'week_no_7', 'week_no_8', 'week_no_9', 'week_no_10', 'week_no_11',\n",
    "       'week_no_12', 'week_no_13', 'week_no_14', 'week_no_15', 'week_no_16',\n",
    "       'week_no_17', 'week_no_18', 'week_no_19', 'week_no_20', 'week_no_21',\n",
    "       'week_no_22', 'week_no_23', 'week_no_24', 'week_no_25', 'week_no_26',\n",
    "       'week_no_27', 'week_no_28', 'week_no_29', 'week_no_30', 'week_no_31',\n",
    "       'week_no_32', 'week_no_33', 'week_no_34', 'week_no_35', 'week_no_36',\n",
    "       'week_no_37', 'week_no_38', 'week_no_39', 'week_no_40', 'week_no_41',\n",
    "       'week_no_42', 'week_no_43', 'week_no_44', 'week_no_45', 'week_no_46',\n",
    "       'week_no_47', 'week_no_48', 'week_no_49', 'week_no_50', 'week_no_51',\n",
    "       'week_no_52', 'color_simple_Black', 'color_simple_Blue',\n",
    "       'color_simple_Brown', 'color_simple_Cream', 'color_simple_Green',\n",
    "       'color_simple_Pink', 'color_simple_White', 'color_simple_Yellow',\n",
    "       'color_simple_Zebra', 'review_-1.0', 'review_1.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knit_data.shape)\n",
    "print(knit_data[knit_data['transaction_date'] < '2021-10-3'].shape)\n",
    "print(knit_data[knit_data['transaction_date'] >= '2021-10-3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_test_train_split_aa(df):\n",
    "   \n",
    "   df_train = df[df['transaction_date'] < '2021-10-3']\n",
    "   df_test = df[df['transaction_date'] >= '2021-10-3']\n",
    "\n",
    "   y_train = df_train['quantity_log']\n",
    "   y_test = df_test['quantity_log']\n",
    "\n",
    "   X_train = df_train.drop(['quantity_log', 'transaction_date'], axis=1)\n",
    "   X_test = df_test.drop(['quantity_log', 'transaction_date'], axis=1)\n",
    " \n",
    "   return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f, X_test_f, y_train_f, y_test_f = temporal_test_train_split_aa(knit_data_full)\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = temporal_test_train_split_aa(knit_data_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_f_ = list(range(2, len(X_train_f.columns))) # \n",
    "max_depth_f_ = list(range(2,10))\n",
    "params_f = []\n",
    "maximum_score_f = -1 ## should be 0 but models are terrible\n",
    "## Random selection of parameters to test\n",
    "random.seed(5)\n",
    "\n",
    "mf_f_ = random.choices(max_features_f_, k=50)\n",
    "md_f_ = random.choices(max_depth_f_, k=50)\n",
    "\n",
    "## Iterations to select best model\n",
    "for i in range (50):\n",
    "    print('model number:',i+1)\n",
    "    #selection of parameters to test\n",
    "    mf_f = mf_f_[i]\n",
    "    md_f = md_f_[i]\n",
    "    print(' parameters:',[mf_f,md_f])\n",
    "    #model\n",
    "    DT_cen = DecisionTreeRegressor(max_features=mf_f,\n",
    "                                    max_depth=md_f,\n",
    "                                    random_state=0\n",
    "                                    ).fit(X_train_f, y_train_f)\n",
    "\n",
    "    # test model on unseen data\n",
    "    y_test_pred_f = DT_cen.predict(X_test_f)\n",
    "    \n",
    "    # take exp of predicted values\n",
    "    y_test_pred_f = np.exp(y_test_pred_f) - 1\n",
    "\n",
    "    score_f = r2_score(np.exp(y_test_f) - 1, y_test_pred_f)\n",
    "    print(' R2:',score_f)\n",
    "\n",
    "    #compare performances on validation data\n",
    "    if score_f > maximum_score_f:\n",
    "        params_f = [mf_f,md_f]\n",
    "        maximum_score_f = score_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best model\n",
    "mf_f,md_f = params_f\n",
    "\n",
    "DT_cen_f = DecisionTreeRegressor(max_features=mf_f,\n",
    "                                max_depth=md_f,\n",
    "                                random_state=0\n",
    "                                ).fit(X_train_f, y_train_f)\n",
    "\n",
    "y_train_pred_f = DT_cen_f.predict(X_train_f)\n",
    "y_train_pred_f = np.exp(y_train_pred_f) - 1\n",
    "\n",
    "y_test_pred_f = DT_cen_f.predict(X_test_f)\n",
    "y_test_pred_f = np.exp(y_test_pred_f) - 1\n",
    "\n",
    "y_train_f = np.exp(y_train_f) - 1\n",
    "y_test_f = np.exp(y_test_f) -1\n",
    "\n",
    "is_r2 = r2_score(y_train_f, y_train_pred_f)\n",
    "oos_r2=r2_score(y_test_f, y_test_pred_f)\n",
    "\n",
    "print('\\nBest Model:')\n",
    "print('Parameters:',params_f)\n",
    "print('IS R2:',is_r2)\n",
    "print('OOS R2:', oos_r2)\n",
    "\n",
    "print('IS MSE', mean_absolute_error(y_train_f, y_train_pred_f))\n",
    "print('OOS MSE', mean_absolute_error(y_test_f, y_test_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_f = pd.DataFrame({'real':y_test_f, 'pred':y_test_pred_f})\n",
    "\n",
    "sns.scatterplot(data=compare_f, x='real', y='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cen_vis_f = DecisionTreeRegressor(max_features=params_f[0],\n",
    "                                            max_depth=params_f[1],\n",
    "                                            random_state=0\n",
    "                                            ).fit(X_train_f, y_train_f)\n",
    "\n",
    "\n",
    "## Print the tree\n",
    "plt.figure(figsize=(15,8), dpi=400)\n",
    "plot_tree(DT_cen_vis_f, feature_names = X_train_f.columns)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_r_ = list(range(2, len(X_train_r.columns))) # \n",
    "max_depth_r_ = list(range(2,10))\n",
    "params_r = []\n",
    "maximum_score_r = -1 ## should be 0 but models are terrible\n",
    "## Random selection of parameters to test\n",
    "random.seed(5)\n",
    "\n",
    "mf_r_ = random.choices(max_features_r_, k=50)\n",
    "md_r_ = random.choices(max_depth_r_, k=50)\n",
    "\n",
    "## Iterations to select best model\n",
    "for i in range (50):\n",
    "    print('model number:',i+1)\n",
    "    #selection of parameters to test\n",
    "    mf_r = mf_r_[i]\n",
    "    md_r = md_r_[i]\n",
    "    print(' parameters:',[mf_r,md_r])\n",
    "    #model\n",
    "    DT_cen = DecisionTreeRegressor(max_features=mf_r,\n",
    "                                    max_depth=md_r,\n",
    "                                    random_state=0\n",
    "                                    ).fit(X_train_r, y_train_r)\n",
    "\n",
    "    # test model on unseen data\n",
    "    y_test_pred_r = DT_cen.predict(X_test_r)\n",
    "    \n",
    "    # take exp of predicted values\n",
    "    y_test_pred_r = np.exp(y_test_pred_r) - 1\n",
    "\n",
    "    score_r = r2_score(np.exp(y_test_r) - 1, y_test_pred_r)\n",
    "    print(' R2:',score_r)\n",
    "\n",
    "    #compare performances on validation data\n",
    "    if score_r > maximum_score_r:\n",
    "        params_r = [mf_r,md_r]\n",
    "        maximum_score_r = score_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best model\n",
    "mf_r,md_r = params_r\n",
    "\n",
    "DT_cen_r = DecisionTreeRegressor(max_features=mf_r,\n",
    "                                max_depth=md_r,\n",
    "                                random_state=0\n",
    "                                ).fit(X_train_r, y_train_r)\n",
    "\n",
    "y_train_pred_r = DT_cen_r.predict(X_train_r)\n",
    "y_train_pred_r = np.exp(y_train_pred_r) - 1\n",
    "\n",
    "y_test_pred_r = DT_cen_r.predict(X_test_r)\n",
    "y_test_pred_r = np.exp(y_test_pred_r) - 1\n",
    "\n",
    "y_train_r = np.exp(y_train_r) - 1\n",
    "y_test_r = np.exp(y_test_r) -1\n",
    "\n",
    "is_r2 = r2_score(y_train_r, y_train_pred_r)\n",
    "oos_r2=r2_score(y_test_r, y_test_pred_r)\n",
    "\n",
    "print('\\nBest Model:')\n",
    "print('Parameters:',params_r)\n",
    "print('IS R2:',is_r2)\n",
    "print('OOS R2:', oos_r2)\n",
    "\n",
    "print('IS MSE', mean_absolute_error(y_train_r, y_train_pred_r))\n",
    "print('OOS MSE', mean_absolute_error(y_test_r, y_test_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_r = DT_cen_r.predict(X_test_r)\n",
    "compare_r = pd.DataFrame({'real':y_test_r, 'pred':y_test_pred_r})\n",
    "\n",
    "sns.scatterplot(data=compare_r, x='real', y='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cen_vis_r = DecisionTreeRegressor(max_features=params_r[0],\n",
    "                                            max_depth=params_r[1],\n",
    "                                            random_state=0\n",
    "                                            ).fit(X_train_r, y_train_r)\n",
    "\n",
    "\n",
    "## Print the tree\n",
    "plt.figure(figsize=(15,8), dpi=400)\n",
    "plot_tree(DT_cen_vis_r, feature_names = X_train_r.columns)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57727d540d2cdea30e42da3b647feb3a70b95224e671f1550702dd816d97d117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
