{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, median_absolute_error)\n",
    "#from autofeat import FeatureSelector, AutoFeatRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = pd.read_csv(\"../data/interim/transactions_sd_knits_resampled_engin_synth_gt.csv\")\n",
    "#knit_data = pd.read_csv(\"../data/interim/transactions_sd_knits_resampled_engin_synth_gt_gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knit_data.groupby(['p_id', 'week_no'])['quantity'].sum().min())\n",
    "print(knit_data.groupby(['p_id', 'week_no'])['quantity'].sum().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data = knit_data)\n",
    "sns.heatmap(knit_data.corr(), annot=True, linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    knit_data['transaction_date'] = pd.to_datetime(knit_data['transaction_date'], infer_datetime_format=True)\n",
    "    knit_data['week_no'] = knit_data['week_no'].astype('object')\n",
    "    knit_data['review'] = knit_data['review'].astype('object')\n",
    "    knit_data.drop(columns=['month'], inplace=True)\n",
    "    knit_data.drop(columns=['p_id'], inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = prepare_data(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_categorical(df):\n",
    "    # one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df) \n",
    "    # drop columns to get k-1 columns for \n",
    "    df_encoded.drop(columns=['week_no_2', 'label_desc_lab_1', 'color_simple_Other', 'review_0.0'], \n",
    "                    axis=1, \n",
    "                    inplace=True)\n",
    "    return df_encoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = one_hot_encode_categorical(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_price_quantity(df):\n",
    "    df['price_log'] = np.log(df['price'] + 1)\n",
    "    df['quantity_log'] = np.log(df['quantity'] + 1)\n",
    "    df.drop(columns=['price'], inplace=True)\n",
    "    df.drop(columns=['quantity'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knit_data = log_price_quantity(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_f1(df):\n",
    "    df = df.drop(columns=['star_rating', 'review_-1.0', 'review_1.0', 'google_trends_knit', 'google_trends_colour'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_f2(df):\n",
    "    df = df.drop(columns=['star_rating', 'review_-1.0', 'review_1.0'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_f3(df):\n",
    "    df = df.drop(columns=['star_rating',\n",
    "       'google_trends_knit', 'google_trends_colour', \n",
    "       'color_simple_Black', 'color_simple_Blue', 'color_simple_Brown',\n",
    "       'color_simple_Cream', 'color_simple_Green', 'color_simple_Pink',\n",
    "       'color_simple_White', 'color_simple_Yellow', 'color_simple_Zebra',\n",
    "       'review_-1.0', 'review_1.0'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knit_data = drop_columns_f3(knit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_test_train_split_aa(df):\n",
    "   \n",
    "   df_train = df[df['transaction_date'] < '2021-10-3']\n",
    "   df_test = df[df['transaction_date'] >= '2021-10-3']\n",
    "\n",
    "   y_train = df_train['quantity_log']\n",
    "   y_test = df_test['quantity_log']\n",
    "\n",
    "   X_train = df_train.drop(['quantity_log', 'transaction_date'], axis=1)\n",
    "   X_test = df_test.drop(['quantity_log', 'transaction_date'], axis=1)\n",
    " \n",
    "   return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = temporal_test_train_split_aa(knit_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try multiple features and tree depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_ = list(range(2, len(X_train.columns))) # \n",
    "max_depth_ = list(range(2,10))\n",
    "params = []\n",
    "minimum_score = 1000 ## \n",
    "\n",
    "## Random selection of parameters to test\n",
    "random.seed(5)\n",
    "\n",
    "mf_ = random.choices(max_features_, k=50)\n",
    "md_ = random.choices(max_depth_, k=50)\n",
    "\n",
    "## Iterations to select best model\n",
    "for i in range (50):\n",
    "    print('model number:',i+1)\n",
    "    #selection of parameters to test\n",
    "    mf = mf_[i]\n",
    "    md = md_[i]\n",
    "    print(' parameters:',[mf,md])\n",
    "    #model\n",
    "    RF_cen = RandomForestRegressor(max_features=mf,\n",
    "                                    max_depth=md,\n",
    "                                    n_estimators=100,\n",
    "                                    random_state=0\n",
    "                                    ).fit(X_train, y_train)\n",
    "\n",
    "    # test model on unseen data\n",
    "    y_test_pred = RF_cen.predict(X_test)\n",
    "    \n",
    "    # take exp of predicted values\n",
    "    y_test_pred = np.exp(y_test_pred) - 1\n",
    "\n",
    "    #score = r2_score(np.log(y_test) - 1, y_test_pred)\n",
    "    #print(' R2:', score)\n",
    "\n",
    "    # evaluate based on MAE - change to median_absolute_error\n",
    "    score = mean_absolute_error(np.log(y_test) - 1, y_test_pred) # evaluate \n",
    "\n",
    "    #compare performances on validation data, minimise mae\n",
    "    if score < minimum_score:\n",
    "        params = [mf,md]\n",
    "        minimum_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best model\n",
    "mf,md = params\n",
    "\n",
    "RF_cen = RandomForestRegressor(max_features=mf,\n",
    "                                max_depth=md,\n",
    "                                n_estimators=100,\n",
    "                                random_state=0\n",
    "                                ).fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = RF_cen.predict(X_train)\n",
    "y_train_pred = np.exp(y_train_pred) - 1\n",
    "\n",
    "y_test_pred = RF_cen.predict(X_test)\n",
    "y_test_pred = np.exp(y_test_pred) - 1\n",
    "\n",
    "y_train = np.exp(y_train) - 1\n",
    "y_test = np.exp(y_test) -1\n",
    "\n",
    "is_r2 = round(r2_score(y_train, y_train_pred), 2)\n",
    "oos_r2 = round(r2_score(y_test, y_test_pred), 2)\n",
    "\n",
    "is_rmse = round(mean_squared_error(y_train, y_train_pred)**0.5, 2)\n",
    "oos_rmse = round(mean_squared_error(y_test, y_test_pred)**0.5, 2)\n",
    "\n",
    "is_mape = round(mean_absolute_percentage_error(y_train, y_train_pred), 2)\n",
    "oos_mape = round(mean_absolute_percentage_error(y_test, y_test_pred), 2)\n",
    "\n",
    "is_mae = round(mean_absolute_error(y_train, y_train_pred), 2)\n",
    "oos_mae = round(mean_absolute_error(y_test, y_test_pred), 2)\n",
    "\n",
    "is_mdape = round(np.median(np.abs((y_train - y_train_pred)/y_train))*100, 2)\n",
    "oos_mdape = round(np.median(np.abs((y_test - y_test_pred)/y_test))*100, 2)\n",
    "\n",
    "is_mdae = round(median_absolute_error(y_train, y_train_pred), 2)\n",
    "oos_mdae = round(median_absolute_error(y_test, y_test_pred), 2)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nBest Model:')\n",
    "print('Parameters:', params)\n",
    "\n",
    "print('IS R2:',is_r2)\n",
    "print('OOS R2:', oos_r2)\n",
    "\n",
    "print('IS RMSE', is_rmse)\n",
    "print('OOS RMSE', oos_rmse)\n",
    "\n",
    "print('IS MAPE', is_mape)\n",
    "print('OOS MAPE', oos_mape)\n",
    "\n",
    "print('IS MAE', is_mae)\n",
    "print('OOS MAE', oos_mae)\n",
    "\n",
    "print('IS MdAPE', is_mdape)\n",
    "print('OOS MdAPE', oos_mdape)\n",
    "\n",
    "print('IS MdAE', is_mdae)\n",
    "print('OOS MdAE', oos_mdae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({'real':y_test, 'pred':y_test_pred})\n",
    "\n",
    "sns.scatterplot(data=compare, x='real', y='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = RF_cen.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/30355159/python-how-to-get-real-feature-name-from-feature-importances\n",
    "feature_importance = pd.DataFrame(columns=['feature', 'importance'])\n",
    "for feature, importance in zip(X_train.columns, RF_cen.feature_importances_):\n",
    "    row_dict = {'feature' : feature, 'importance' : importance}\n",
    "    feature_importance = feature_importance.append(row_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return weight of features in order of importance\n",
    "feature_names = X_train.columns\n",
    "coef = RF_cen.feature_importances_\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(abs(coef))[::-1]\n",
    "#print(indices)\n",
    "#print(feature_names[indices.astype(int)])\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57727d540d2cdea30e42da3b647feb3a70b95224e671f1550702dd816d97d117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
