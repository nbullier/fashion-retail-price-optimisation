{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = \"../data/raw\" \n",
    "prod_data = pd.read_excel(\"../data/raw/Product_data.xlsx\", sheet_name=\"Data\")\n",
    "trans_data = pd.read_excel(\"../data/raw/Transaction_data.xlsx\", sheet_name=\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_product_transactions(product_data=prod_data, transaction_data=trans_data):\n",
    "    '''\n",
    "    Returns a merged dataframe of product data and transaction data.\n",
    "        Parameters:\n",
    "            product_data (df): A dataframe containing product information\n",
    "            transaction_data (df): A dataframe containing transaction information.\n",
    "        Returns:\n",
    "            merged_data (df): A dataframe containing prodcut and transaction data, merged on sku.\n",
    "    '''\n",
    "    merged_data = pd.merge(prod_data, trans_data, on=\"sku\", how=\"right\")\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merge_product_transactions(product_data=prod_data, transaction_data=trans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove characters from the p_id_x / p_id_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_pid_cols(df):\n",
    "    '''\n",
    "    Removes extra characters from product ID (p_id) column.\n",
    "        Parameters:\n",
    "            df (df): Dataframe from which to remove extra characters from p_id column.\n",
    "        Returns:\n",
    "            df (df): A dataframe with extra characters removed from the product ID (p_id) column.\n",
    "    '''\n",
    "    merged_data['p_id'] = merged_data['p_id_y'].astype('str').str.replace(r'v\\d', '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = fix_pid_cols(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['p_id'].isna().value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which sub-department has the most transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.groupby(['sub_department_desc']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many product types exist within knits and dresses?\n",
    "\n",
    "print('unique products in knits (p_id): ' + str(merged_data[merged_data['sub_department_desc'] == 'W L/S KNITS']['p_id'].nunique()))\n",
    "print('unique products in knits (p_id_x): ' + str(merged_data[merged_data['sub_department_desc'] == 'W L/S KNITS']['p_id_x'].nunique()))\n",
    "print('unique products in knits (p_id_y): ' + str(merged_data[merged_data['sub_department_desc'] == 'W L/S KNITS']['p_id_y'].nunique()))\n",
    "print('unique products in knits (style): ' + str(merged_data[merged_data['sub_department_desc'] == 'W L/S KNITS']['style'].nunique()))\n",
    "\n",
    "print('unique products in dresses (p_id): ' + str(merged_data[merged_data['sub_department_desc'] == 'DRESSES']['p_id'].nunique()))\n",
    "print('unique products in dresses (p_id_x): ' + str(merged_data[merged_data['sub_department_desc'] == 'DRESSES']['p_id_x'].nunique()))\n",
    "print('unique products in dresses (p_id_y): ' + str(merged_data[merged_data['sub_department_desc'] == 'DRESSES']['p_id_y'].nunique()))\n",
    "print('unique products in dresses (style): ' + str(merged_data[merged_data['sub_department_desc'] == 'DRESSES']['style'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[merged_data['sub_department_desc'] == 'W L/S KNITS'][['p_id', 'p_id_x', 'p_id_y', 'style']].drop_duplicates().sort_values('style')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplify colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_colours(df):\n",
    "    '''\n",
    "    Simplifies colours present in the 'color' column of dataframe.\n",
    "        Parameters:\n",
    "            df (df): Dataframe in which to simplify colours.\n",
    "        Returns: \n",
    "            df (df): A dataframe containing an extra column 'color_simple' that contains simplified colours.\n",
    "    '''\n",
    "    df['color_simple'] = df['color']\n",
    "\n",
    "    contains_colour = ['Windsor Heather',  'Zoe Wash', 'Woodbury Strp Wh/Hydran/G',\n",
    "       'Woodburn Patchwork', 'Wooster/Alley', 'Woodley Plaid',\n",
    "       'York Pld/Oxford Pld Gld', 'Watercolor Print 1', 'Vintage Sailboat',\n",
    "       'Wiggins', 'Winona Wash', 'Vintage Port Multi', 'Williams Wash'\n",
    "       ,'Yucatan','Rose','Gold','Wine','Navy','Royal','Wisteria','Whiskey','Coral',\n",
    "       'Lavender','Tan','Khaki','Camo','Taupe','Wildflower','Floral','Hibiscus','Silver',\n",
    "       'Pepper','Vicuna','Washed Forest','Mauve','Camel','Light Indigo','Whyskey','Windsor Heather Multi Str',\n",
    "       'Woodbridge Olive','Yuca Tan','Yanda Wash','White','Zebra','Blue','Cream','Navy','Grey','Orange',\n",
    "       'Green','Red','Rose','Mauve','Purple','Black','Pink','Brown','Yellow']\n",
    "\n",
    "    replace_colour = ['Other','Other','Other','Other','Other','Other','Other','Other','Other','Other','Other',\n",
    "        'Other','Other','Other','Pink','Yellow','Purple','Blue','Blue','Purple','Brown','Red','Purple','Brown','Green',\n",
    "        'Green','Brown','Floral','Floral','Pink','Grey','Grey','Brown','Green','Purple','Brown','Blue','Brown','Windsor Heather',\n",
    "        'Green','Yucatan','White','White','Zebra','Blue','Cream','Navy','Grey','Orange','Green','Red','Rose','Mauve','Purple','Black',\n",
    "        'Pink','Brown','Yellow']\n",
    "        \n",
    "    for ii in range(len(df['color_simple'])):\n",
    "        for jj in range(len(contains_colour)):\n",
    "            if contains_colour[jj] in df['color_simple'][ii]: \n",
    "                df['color_simple'][ii] = replace_colour[jj]\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = simplify_colours(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select columns of interest, sub-category of interest and positive transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_category(df):\n",
    "    '''\n",
    "    Creates a new dataframe that contains columns to take forward to the next step, rows matching the 'W L/S KNITS' subdepartment, \n",
    "    and rows deonoting positive transactions.\n",
    "        Parameters:\n",
    "            df (df): Dataframe from which to extract columns and rows.\n",
    "        Returns:\n",
    "            df (df): Dataframe containing columns and rows of interest.\n",
    "\n",
    "    '''\n",
    "    df = df[['p_id', 'transaction_date', 'sub_department_desc', 'label_desc', 'color_simple', 'quantity', 'amount']]\n",
    "    df = df[df['sub_department_desc'] == 'W L/S KNITS']\n",
    "    df = df[df['amount'] > 0]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_pruned_sd_knits = select_columns_category(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_pruned_sd_knits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write data to interim folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_pruned_sd_knits.to_csv(\"../data/interim/transactions_sd_knits.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57727d540d2cdea30e42da3b647feb3a70b95224e671f1550702dd816d97d117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
